import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
matplotlib.use('agg')  # Set backend before importing pyplot
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report
from scipy.stats import skew, kurtosis
import io
import datetime

# C·∫•u h√¨nh trang Streamlit
st.set_page_config(
    page_title="Ph√¢n lo·∫°i h·ªçc sinh",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Th√™m m·ªôt ch√∫t CSS t√πy ch·ªânh ƒë·ªÉ l√†m ƒë·∫πp
st.markdown("""
<style>
/* Gradient background for the entire app */
.stApp {
    background: linear-gradient(135deg, #2A0845 0%, #6441A5 100%);
}

/* Main header styling */
.main-header {
    font-size: 2.5em;
    color: #fff;
    text-align: center;
    margin-bottom: 20px;
    text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
}

/* Card-like containers for content */
.content-card {
    background: rgba(255, 255, 255, 0.1);
    border-radius: 15px;
    padding: 20px;
    margin: 10px 0;
    backdrop-filter: blur(10px);
    border: 1px solid rgba(255, 255, 255, 0.2);
}

/* Tab styling */
.stTabs [data-baseweb="tab-list"] {
    gap: 20px;
    background: rgba(255, 255, 255, 0.1);
    padding: 10px;
    border-radius: 10px;
}

.stTabs [data-baseweb="tab"] {
    height: 50px;
    white-space: nowrap;
    background: rgba(255, 255, 255, 0.2);
    border-radius: 7px;
    gap: 10px;
    padding: 0 20px;
    transition: all 0.3s ease;
}

.stTabs [data-baseweb="tab"]:hover {
    background: rgba(255, 255, 255, 0.3);
    transform: translateY(-2px);
}

.stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
    background: rgba(138, 43, 226, 0.6);
    color: white;
    border-bottom: 3px solid #FFD700;
}

/* Button styling */
.stButton>button {
    background: linear-gradient(45deg, #8A2BE2, #9932CC);
    color: white;
    border-radius: 8px;
    padding: 10px 25px;
    font-size: 1em;
    font-weight: bold;
    border: none;
    transition: all 0.3s ease;
}

.stButton>button:hover {
    transform: translateY(-2px);
    box-shadow: 0 5px 15px rgba(138, 43, 226, 0.4);
}

/* DataFrames and other containers */
.stDataFrame {
    border: 1px solid rgba(255, 255, 255, 0.2);
    border-radius: 10px;
    background: rgba(255, 255, 255, 0.05);
}

/* Text colors for better visibility */
.streamlit-expanderHeader, .stMarkdown, .stText, .stAlert, .stInfo, .stWarning, .stSuccess, .st-ay {
    color: #fff !important;
}
</style>
""", unsafe_allow_html=True)

# Add decorative header with image
st.markdown("""
<div style='text-align: center; padding: 20px;'>
    <h1 class='main-header'>H·ªá th·ªëng ph√¢n lo·∫°i h·ªçc sinh <br>d·ª±a tr√™n th√†nh t√≠ch v√† h√†nh vi h·ªçc t·∫≠p</h1>
    <h2 class='main-header' style='font-size:1.5em;'>NH√ìM 3</h2>
</div>
""", unsafe_allow_html=True)

# Add decorative icons using emoji instead of external images
st.markdown("""
<div class='content-card'>
    <div style='display: flex; justify-content: space-around; align-items: center; flex-wrap: wrap; gap: 20px;'>
        <div style='text-align: center;'>
            <div style='font-size: 50px;'>üë®‚Äçüè´</div>
            <p style='color: white;'>Hu·∫•n luy·ªán</p>
        </div>
        <div style='text-align: center;'>
            <div style='font-size: 50px;'>üìä</div>
            <p style='color: white;'>Ph√¢n t√≠ch</p>
        </div>
        <div style='text-align: center;'>
            <div style='font-size: 50px;'>üéØ</div>
            <p style='color: white;'>D·ª± ƒëo√°n</p>
        </div>
    </div>
</div>
""", unsafe_allow_html=True)


# Bi·∫øn to√†n c·ª•c ƒë·ªÉ l∆∞u tr·ªØ encoder v√† c·ªôt hu·∫•n luy·ªán
# S·ª≠ d·ª•ng st.session_state ƒë·ªÉ gi·ªØ tr·∫°ng th√°i gi·ªØa c√°c l·∫ßn rerun c·ªßa Streamlit
if 'grade_encoder' not in st.session_state:
    st.session_state['grade_encoder'] = None
if 'X_train_cols' not in st.session_state:
    st.session_state['X_train_cols'] = None
if 'rf_model' not in st.session_state:
    st.session_state['rf_model'] = None
if 'uploaded_train_file_content' not in st.session_state:
    st.session_state['uploaded_train_file_content'] = None # L∆∞u n·ªôi dung file ƒë·ªÉ cache
if 'uploaded_predict_file_content' not in st.session_state:
    st.session_state['uploaded_predict_file_content'] = None # L∆∞u n·ªôi dung file ƒë·ªÉ cache
if 'training_report_content' not in st.session_state:
    st.session_state['training_report_content'] = None # L∆∞u n·ªôi dung b√°o c√°o hu·∫•n luy·ªán


# H√†m t·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu
@st.cache_data(show_spinner=False) # Cache d·ªØ li·ªáu ƒë·ªÉ kh√¥ng x·ª≠ l√Ω l·∫°i n·∫øu file kh√¥ng ƒë·ªïi, ·∫©n spinner m·∫∑c ƒë·ªãnh
def load_and_preprocess_data(uploaded_file_buffer, is_prediction_data=False):
    """
    T·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu.
    Bao g·ªìm √°nh x·∫° Grade, x·ª≠ l√Ω missing value, one-hot encoding v√† x·ª≠ l√Ω skew/kurtosis.
    """
    df = None
    if uploaded_file_buffer is not None:
        try:
            df = pd.read_csv(uploaded_file_buffer)
        except Exception as e:
            st.error(f"L·ªói khi ƒë·ªçc file CSV: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file v√† ƒë·∫£m b·∫£o file kh√¥ng tr·ªëng.")
            return None, None
    else:
        # Ch·ªâ t·∫°o d·ªØ li·ªáu m·∫´u n·∫øu kh√¥ng ph·∫£i l√† d·ªØ li·ªáu d·ª± ƒëo√°n
        if not is_prediction_data:
            st.warning("Kh√¥ng c√≥ file d·ªØ li·ªáu ƒë∆∞·ª£c t·∫£i l√™n. ƒêang s·ª≠ d·ª•ng d·ªØ li·ªáu m·∫´u gi·∫£ l·∫≠p.")
            data = {
                'G1': np.random.randint(0, 20, 200),
                'G2': np.random.randint(0, 20, 200),
                'G3': np.random.randint(0, 20, 200),
                'Final_Score': np.random.randint(0, 100, 200),
                'Quizzes_Avg': np.random.randint(0, 100, 200),
                'Sleep_Hours_per_Night': np.random.randint(4, 10, 200),
                'Assignments_Avg': np.random.randint(0, 100, 200),
                'Internet_Access_at_Home': np.random.choice(['Yes', 'No'], 200),
                'Parent_Education_Level': np.random.choice(['High School', 'College', 'University', 'Masters'], 200),
                'Attendance (%)': np.random.randint(50, 100, 200)
            }
            df = pd.DataFrame(data)
            # Fill NaNs in sample data just in case
            for col in df.select_dtypes(include='object').columns:
                if df[col].isnull().any():
                    df[col] = df[col].fillna(df[col].mode()[0])
            for col in df.select_dtypes(include=np.number).columns:
                if df[col].isnull().any():
                    df[col] = df[col].fillna(df[col].mean())
        else: # N·∫øu l√† d·ªØ li·ªáu d·ª± ƒëo√°n nh∆∞ng kh√¥ng c√≥ file
            return None, None

    if df is None or df.empty: # Tr∆∞·ªùng h·ª£p l·ªói ho·∫∑c kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ x·ª≠ l√Ω
        st.error("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng ki·ªÉm tra file ƒë·∫ßu v√†o.")
        return None, None

    st.subheader("üìä D·ªØ li·ªáu g·ªëc ƒë√£ t·∫£i l√™n:")
    st.dataframe(df.head())
    st.write(f"K√≠ch th∆∞·ªõc d·ªØ li·ªáu: `{df.shape[0]}` h√†ng, `{df.shape[1]}` c·ªôt")

    # Ki·ªÉm tra c√°c c·ªôt c·∫ßn thi·∫øt
    required_initial_cols = ['G1', 'G2', 'G3', 'Final_Score', 'Quizzes_Avg', 'Sleep_Hours_per_Night', 'Assignments_Avg', 'Internet_Access_at_Home', 'Parent_Education_Level', 'Attendance (%)']
    missing_initial_cols = [col for col in required_initial_cols if col not in df.columns]
    
    has_g_cols = all(col in df.columns for col in ['G1', 'G2', 'G3'])
    has_final_score = 'Final_Score' in df.columns

    if not has_g_cols and not has_final_score:
        st.error("D·ªØ li·ªáu thi·∫øu c√°c c·ªôt ƒëi·ªÉm c·∫ßn thi·∫øt (G1, G2, G3 ho·∫∑c Final_Score). Kh√¥ng th·ªÉ ti·∫øp t·ª•c ph√¢n t√≠ch.")
        return None, None

    if missing_initial_cols and (has_g_cols or has_final_score):
        st.warning(f"D·ªØ li·ªáu c√≥ th·ªÉ thi·∫øu m·ªôt s·ªë c·ªôt khuy·∫øn ngh·ªã: `{', '.join(missing_initial_cols)}`. ƒêang ti·∫øp t·ª•c v·ªõi c√°c c·ªôt hi·ªán c√≥.")

    st.subheader("‚öôÔ∏è Kh√°m ph√° d·ªØ li·ªáu v√† Ti·ªÅn x·ª≠ l√Ω:")

    # √Ånh x·∫° ƒëi·ªÉm th√†nh Grade
    def map_grade(score):
        if score < 30:
            return 'Weak'
        elif score < 40:
            return 'Average'
        elif score < 50:
            return 'Good'
        else:
            return 'Excellent'

    # T√≠nh total_grade d·ª±a tr√™n c√°c c·ªôt c√≥ s·∫µn
    if has_g_cols:
        df['total_grade'] = df['G1'] + df['G2'] + df['G3']
    elif has_final_score:
        df['total_grade'] = df['Final_Score'] / 100 * 60 # Scale Final_Score to be comparable if needed
    else:
        st.error("Kh√¥ng th·ªÉ t·∫°o c·ªôt 'total_grade' v√¨ thi·∫øu c·∫£ G1, G2, G3 v√† Final_Score.")
        return None, None

    df['Grade'] = df['total_grade'].apply(map_grade)
    st.write("D·ªØ li·ªáu sau khi th√™m c·ªôt 'Grade':")
    st.dataframe(df.head())
    
    # Bi·ªÉu ƒë·ªì ph√¢n ph·ªëi Grade sau khi mapping
    st.write("Ph√¢n ph·ªëi c√°c lo·∫°i Grade:")
    fig_grade_dist, ax_grade_dist = plt.subplots(figsize=(7, 5))
    sns.countplot(x='Grade', data=df, ax=ax_grade_dist, order=['Weak', 'Average', 'Good', 'Excellent'], palette='viridis')
    ax_grade_dist.set_title("Ph√¢n ph·ªëi h·ªçc l·ª±c")
    st.pyplot(fig_grade_dist)
    plt.close(fig_grade_dist)

    # X·ª≠ l√Ω Missing Value (lo·∫°i b·ªè c√°c h√†ng c√≥ NaN)
    initial_rows = df.shape[0]
    df.dropna(inplace=True)
    st.write(f"ƒê√£ lo·∫°i b·ªè `{initial_rows - df.shape[0]}` h√†ng ch·ª©a gi√° tr·ªã thi·∫øu (NaN).")
    st.dataframe(df.head())

    if df.empty:
        st.error("D·ªØ li·ªáu tr·ªëng sau khi lo·∫°i b·ªè c√°c h√†ng c√≥ gi√° tr·ªã thi·∫øu. Vui l√≤ng ki·ªÉm tra d·ªØ li·ªáu c·ªßa b·∫°n.")
        return None, None

    # Category Encoding cho c·ªôt 'Grade'
    encoder = LabelEncoder()
    df['Grade_encoded'] = encoder.fit_transform(df['Grade'])
    
    # One-hot encoding cho c√°c c·ªôt category kh√°c
    object_columns = df.select_dtypes(include=['object', 'category']).columns.drop(['Grade'], errors='ignore')
    if len(object_columns) > 0:
        df = pd.get_dummies(df, columns=object_columns, drop_first=True, dtype='int')
        st.write("D·ªØ li·ªáu sau khi One-Hot Encoding c√°c c·ªôt ph√¢n lo·∫°i:")
        st.dataframe(df.head())
    else:
        st.write("Kh√¥ng c√≥ c·ªôt ki·ªÉu object/category n√†o kh√°c ƒë·ªÉ th·ª±c hi·ªán One-Hot Encoding.")

    # Ph√¢n t√≠ch ph√¢n ph·ªëi v√† x·ª≠ l√Ω skewness/kurtosis
    st.subheader("üìà Ph√¢n t√≠ch ph√¢n ph·ªëi v√† x·ª≠ l√Ω ƒë·ªô l·ªách/ƒë·ªô nh·ªçn")
    numeric_cols = df.select_dtypes(include=np.number).columns.drop(['Grade_encoded', 'total_grade'], errors='ignore')
    
    # Bi·ªÉu ƒë·ªì ma tr·∫≠n t∆∞∆°ng quan sau ti·ªÅn x·ª≠ l√Ω
    st.write("Ma tr·∫≠n t∆∞∆°ng quan c·ªßa c√°c bi·∫øn s·ªë sau ti·ªÅn x·ª≠ l√Ω:")
    if not numeric_cols.empty and len(numeric_cols) > 1:
        fig_corr_processed, ax_corr_processed = plt.subplots(figsize=(10, 8))
        sns.heatmap(df[numeric_cols].corr(), annot=True, fmt=".2f", cmap='coolwarm', ax=ax_corr_processed)
        ax_corr_processed.set_title("Ma tr·∫≠n t∆∞∆°ng quan sau ti·ªÅn x·ª≠ l√Ω")
        st.pyplot(fig_corr_processed)
        plt.close(fig_corr_processed)
    else:
        st.info("Kh√¥ng ƒë·ªß c·ªôt s·ªë ƒë·ªÉ v·∫Ω ma tr·∫≠n t∆∞∆°ng quan sau ti·ªÅn x·ª≠ l√Ω.")

    for col in numeric_cols:
        if col in df.columns: # Ki·ªÉm tra l·∫°i c·ªôt c√≥ t·ªìn t·∫°i kh√¥ng sau c√°c ph√©p bi·∫øn ƒë·ªïi
            st.markdown(f"##### C·ªôt: `{col}`")
            col1, col2 = st.columns(2)
            
            with col1:
                st.write(f"Ph√¢n ph·ªëi g·ªëc c·ªßa c·ªôt `{col}`:")
                fig_hist, ax_hist = plt.subplots()
                sns.histplot(df[col], kde=True, ax=ax_hist, color='skyblue')
                ax_hist.set_title(f'Ph√¢n ph·ªëi c·ªßa {col}')
                st.pyplot(fig_hist)
                plt.close(fig_hist)

            sk = skew(df[col])
            kt = kurtosis(df[col])
            st.write(f"ƒê·ªô l·ªách (Skewness): `{sk:.2f}`")
            st.write(f"ƒê·ªô nh·ªçn (Kurtosis): `{kt:.2f}`")

            original_skew = skew(df[col])
            transformation_applied = False
            if abs(original_skew) > 1:
                if original_skew > 1:
                    # Add a small constant to avoid log(0) if min value is 0 or negative
                    df[col] = np.log1p(df[col]) 
                    st.write(f"-> ƒê√£ √°p d·ª•ng Log transformation cho c·ªôt `{col}` do ƒë·ªô l·ªách d∆∞∆°ng l·ªõn.")
                    transformation_applied = True
                elif original_skew < -1:
                    st.write(f"-> C·ªôt `{col}` c√≥ ƒë·ªô l·ªách √¢m. Kh√¥ng √°p d·ª•ng bi·∫øn ƒë·ªïi t·ª± ƒë·ªông.")
            
            if transformation_applied:
                with col2:
                    st.write(f"Ph√¢n ph·ªëi c·ªßa `{col}` sau x·ª≠ l√Ω ƒë·ªô l·ªách:")
                    fig_hist_skew, ax_hist_skew = plt.subplots()
                    sns.histplot(df[col], kde=True, ax=ax_hist_skew, color='lightcoral')
                    ax_hist_skew.set_title(f'Ph√¢n ph·ªëi c·ªßa {col} sau x·ª≠ l√Ω')
                    st.pyplot(fig_hist_skew)
                    plt.close(fig_hist_skew)
                st.write(f"ƒê·ªô l·ªách (Skewness) sau x·ª≠ l√Ω: `{skew(df[col]):.2f}`")
            st.markdown("---") # ƒê∆∞·ªùng ph√¢n c√°ch gi·ªØa c√°c c·ªôt

    return df, encoder

# H√†m t·∫°o b√°o c√°o hu·∫•n luy·ªán d∆∞·ªõi d·∫°ng chu·ªói Markdown/Text
def create_training_report_content(accuracy, confusion_matrix_data, classification_report_text, grade_classes):
    report_string = io.StringIO()
    
    report_string.write(f"# B√°o c√°o Hu·∫•n luy·ªán v√† ƒê√°nh gi√° M√¥ h√¨nh Ph√¢n lo·∫°i H·ªçc sinh\n\n")
    report_string.write(f"Ng√†y v√† gi·ªù t·∫°o b√°o c√°o: {datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
    report_string.write("---\n\n")

    report_string.write("## 1. T·ªïng quan hi·ªáu su·∫•t m√¥ h√¨nh\n")
    report_string.write(f"- Accuracy tr√™n t·∫≠p ki·ªÉm tra: **{accuracy:.4f}**\n\n")

    report_string.write("## 2. Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)\n")
    report_string.write("Ma tr·∫≠n n√†y cho th·∫•y s·ªë l∆∞·ª£ng c√°c d·ª± ƒëo√°n ƒë√∫ng v√† sai c·ªßa m√¥ h√¨nh cho t·ª´ng l·ªõp.\n")
    
    cm_df = pd.DataFrame(confusion_matrix_data, index=grade_classes, columns=grade_classes)
    report_string.write("```\n")
    report_string.write(cm_df.to_string())
    report_string.write("\n```\n\n")

    report_string.write("## 3. B√°o c√°o ph√¢n lo·∫°i (Classification Report)\n")
    report_string.write("B√°o c√°o n√†y cung c·∫•p c√°c ch·ªâ s·ªë Precision, Recall, F1-score v√† Support cho t·ª´ng l·ªõp h·ªçc l·ª±c.\n")
    report_string.write("```\n")
    report_string.write(classification_report_text)
    report_string.write("\n```\n\n")
    
    report_string.write("## 4. Ghi ch√∫\n")
    report_string.write("M√¥ h√¨nh Random Forest ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v·ªõi c√°c tham s·ªë v√† quy tr√¨nh ti·ªÅn x·ª≠ l√Ω ƒë∆∞·ª£c m√¥ t·∫£ trong ·ª©ng d·ª•ng.\n")
    report_string.write("K·∫øt qu·∫£ n√†y c√≥ th·ªÉ thay ƒë·ªïi t√πy thu·ªôc v√†o d·ªØ li·ªáu ƒë·∫ßu v√†o v√† c√°c tham s·ªë m√¥ h√¨nh.\n\n")
    report_string.write("---\n")
    report_string.write("B√°o c√°o ƒë∆∞·ª£c t·∫°o t·ª± ƒë·ªông b·ªüi H·ªá th·ªëng ph√¢n lo·∫°i h·ªçc sinh (Nh√≥m 3).\n")

    return report_string.getvalue()

def train_and_evaluate_model(df_processed, grade_encoder):
    """Function to encapsulate the training and evaluation logic."""
    if df_processed is None or grade_encoder is None:
        st.error("Kh√¥ng c√≥ d·ªØ li·ªáu h·ª£p l·ªá ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.")
        return

    st.markdown("### 2.1. Hu·∫•n luy·ªán m√¥ h√¨nh")
    X = df_processed.drop(['Grade', 'Grade_encoded', 'total_grade'], axis=1, errors='ignore')
    y = df_processed['Grade_encoded']

    # Handle infinite values if any (from log transform on very small numbers)
    X = X.replace([np.inf, -np.inf], np.nan)
    # Drop columns that became entirely NaN after transformations if any
    X = X.dropna(axis=1)

    st.session_state['X_train_cols'] = X.columns.tolist()

    if len(X) < 2 or len(y.unique()) < 2:
        st.error("D·ªØ li·ªáu kh√¥ng ƒë·ªß ƒë·ªÉ chia t·∫≠p hu·∫•n luy·ªán/ki·ªÉm tra ho·∫∑c ch·ªâ c√≥ m·ªôt l·ªõp duy nh·∫•t. Vui l√≤ng cung c·∫•p th√™m d·ªØ li·ªáu ƒëa d·∫°ng h∆°n.")
        return

    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

    st.write(f"K√≠ch th∆∞·ªõc t·∫≠p hu·∫•n luy·ªán: `{X_train.shape}`")
    st.write(f"K√≠ch th∆∞·ªõc t·∫≠p ki·ªÉm tra: `{X_test.shape}`")
    
    with st.expander("Xem ph√¢n ph·ªëi l·ªõp trong t·∫≠p hu·∫•n luy·ªán"):
        st.write("Ph√¢n ph·ªëi l·ªõp trong t·∫≠p hu·∫•n luy·ªán:")
        # Map encoded labels back to original class names for better readability
        fig_train_dist, ax_train_dist = plt.subplots(figsize=(7, 5))
        sns.countplot(x=y_train.map(dict(enumerate(grade_encoder.classes_))), ax=ax_train_dist, palette='viridis')
        ax_train_dist.set_title("Ph√¢n ph·ªëi l·ªõp h·ªçc l·ª±c trong t·∫≠p hu·∫•n luy·ªán")
        ax_train_dist.set_xlabel("H·ªçc l·ª±c")
        ax_train_dist.set_ylabel("S·ªë l∆∞·ª£ng")
        st.pyplot(fig_train_dist)
        plt.close(fig_train_dist)

    st.info("ƒêang hu·∫•n luy·ªán m√¥ h√¨nh Random Forest... üöÄ")
    with st.spinner("M√¥ h√¨nh ƒëang ƒë∆∞·ª£c hu·∫•n luy·ªán... Qu√° tr√¨nh n√†y c√≥ th·ªÉ m·∫•t v√†i gi√¢y."):
        rf_model = RandomForestClassifier(
            n_estimators=100,
            max_depth=10,
            class_weight='balanced',
            random_state=42
        )
        rf_model.fit(X_train, y_train)
        st.session_state['rf_model'] = rf_model
    st.success("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán th√†nh c√¥ng!")

    st.markdown("### 2.2. ƒê√°nh gi√° m√¥ h√¨nh")
    y_pred = rf_model.predict(X_test)
    acc = accuracy_score(y_test, y_pred)
    st.markdown(f"<h3 style='color:#00FF00;'>Accuracy c·ªßa m√¥ h√¨nh tr√™n t·∫≠p ki·ªÉm tra: <span style='font-weight:bold;'>{acc:.4f}</span></h3>", unsafe_allow_html=True) # M√†u xanh l√°

    # L·∫•y confusion matrix v√† classification report
    cm = confusion_matrix(y_test, y_pred)
    report = classification_report(y_test, y_pred, target_names=grade_encoder.classes_)

    with st.expander("Xem Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)"):
        st.markdown("#### Ma tr·∫≠n nh·∫ßm l·∫´n (Confusion Matrix)")
        fig_cm, ax_cm = plt.subplots(figsize=(8, 6))
        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax_cm,
                    xticklabels=grade_encoder.classes_,
                    yticklabels=grade_encoder.classes_)
        ax_cm.set_xlabel("D·ª± ƒëo√°n")
        ax_cm.set_ylabel("Th·ª±c t·∫ø")
        ax_cm.set_title("Confusion Matrix")
        st.pyplot(fig_cm)
        plt.close(fig_cm)

    with st.expander("Xem B√°o c√°o ph√¢n lo·∫°i (Classification Report)"):
        st.markdown("#### B√°o c√°o ph√¢n lo·∫°i (Classification Report)")
        st.code(report)
            
    # Sau khi t·∫•t c·∫£ ƒë√°nh gi√° ho√†n t·∫•t, t·∫°o v√† l∆∞u b√°o c√°o
    st.session_state['training_report_content'] = create_training_report_content(
        acc, cm, report, grade_encoder.classes_
    )

    # N√∫t t·∫£i b√°o c√°o
    st.markdown("### 2.3. T·∫£i b√°o c√°o hu·∫•n luy·ªán")
    st.download_button(
        label="T·∫£i xu·ªëng B√°o c√°o Hu·∫•n luy·ªán & ƒê√°nh gi√° (TXT) üìÑ",
        data=st.session_state['training_report_content'],
        file_name="bao_cao_huan_luyen_mo_hinh_hoc_sinh.txt",
        mime="text/plain",
        key="download_training_report"
    )

# --- T·∫°o c√°c Tabs ---
st.markdown("""
<style>
    .stTabs [data-baseweb="tab-list"] button[aria-selected="false"] {
        background-color: #E6E6FA;  /* N·ªÅn t√≠m nh·∫°t khi ch∆∞a ch·ªçn */
        color: black;   /* Ch·ªØ ƒëen khi ch∆∞a ch·ªçn */
    }
    .stTabs [data-baseweb="tab-list"] button[aria-selected="true"] {
        background-color: #8A2BE2;  /* N·ªÅn t√≠m ƒë·∫≠m khi ƒë√£ ch·ªçn */
        color: white;   /* Ch·ªØ tr·∫Øng khi ƒë√£ ch·ªçn */
    }
</style>
""", unsafe_allow_html=True)

tab_intro, tab_train_eval, tab_predict = st.tabs(["Gi·ªõi thi·ªáu üìö", "Hu·∫•n luy·ªán & ƒê√°nh gi√° M√¥ h√¨nh üìà", "D·ª± ƒëo√°n D·ªØ li·ªáu M·ªõi üîÆ"])

with tab_intro:
    st.markdown("## Ch√†o m·ª´ng ƒë·∫øn v·ªõi H·ªá th·ªëng Ph√¢n lo·∫°i H·ªçc sinh!")
    st.markdown("""
    <div class='content-card'>
        <p style="font-size: 1.1em; color: #E0FFFF;">
            ·ª®ng d·ª•ng n√†y ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ ph√¢n lo·∫°i h·ªçc l·ª±c c·ªßa h·ªçc sinh (<b>Weak, Average, Good, Excellent</b>) 
            d·ª±a tr√™n c√°c y·∫øu t·ªë li√™n quan ƒë·∫øn th√†nh t√≠ch h·ªçc t·∫≠p v√† h√†nh vi. M·ª•c ti√™u l√† gi√∫p gi√°o vi√™n v√† ph·ª• huynh 
            c√≥ c√°i nh√¨n s√¢u s·∫Øc h∆°n v·ªÅ t√¨nh h√¨nh h·ªçc t·∫≠p c·ªßa h·ªçc sinh.
        </p>
    </div>
    """, unsafe_allow_html=True)
    
    st.markdown("### üîç C√°ch s·ª≠ d·ª•ng ·ª©ng d·ª•ng:")
    st.markdown("""
    <ul style="list-style-type: square; color: #E0FFFF;">
        <li><b><span style="color: #FFD700;">Tab 'Hu·∫•n luy·ªán & ƒê√°nh gi√° M√¥ h√¨nh'</span>:</b>
            <ul>
                <li>T·∫£i l√™n file d·ªØ li·ªáu <code>CSV</code> c·ªßa b·∫°n (v√≠ d·ª•: <code>student_data.csv</code>) ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh.</li>
                <li>·ª®ng d·ª•ng s·∫Ω t·ª± ƒë·ªông th·ª±c hi·ªán c√°c b∆∞·ªõc ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu v√† hu·∫•n luy·ªán m√¥ h√¨nh Random Forest.</li>
                <li>B·∫°n s·∫Ω th·∫•y c√°c b√°o c√°o ƒë√°nh gi√° hi·ªáu su·∫•t m√¥ h√¨nh nh∆∞ Accuracy, Confusion Matrix, v√† Classification Report.</li>
            </ul>
        </li>
        <li><b><span style="color: #FFD700;">Tab 'D·ª± ƒëo√°n D·ªØ li·ªáu M·ªõi'</span>:</b>
            <ul>
                <li>Sau khi m√¥ h√¨nh ƒë∆∞·ª£c hu·∫•n luy·ªán, b·∫°n c√≥ th·ªÉ t·∫£i l√™n m·ªôt file <code>CSV</code> ch·ª©a d·ªØ li·ªáu c·ªßa c√°c h·ªçc sinh m·ªõi.</li>
                <li>M√¥ h√¨nh s·∫Ω d·ª± ƒëo√°n h·ªçc l·ª±c cho t·ª´ng h·ªçc sinh v√† hi·ªÉn th·ªã k·∫øt qu·∫£ c√πng ph√¢n ph·ªëi h·ªçc l·ª±c d·ª± ƒëo√°n.</li>
            </ul>
        </li>
    </ul>
    """, unsafe_allow_html=True)
    
    st.markdown("---")
    st.markdown("### üß† V·ªÅ thu·∫≠t to√°n Random Forest:")
    st.markdown("""
    <div class='content-card'>
        <p style="font-style: italic; color: #E0FFFF;">
        Random Forest l√† m·ªôt thu·∫≠t to√°n h·ªçc m√°y m·∫°nh m·∫Ω, thu·ªôc h·ªç c√°c thu·∫≠t to√°n h·ªçc t·∫≠p ensemble. 
        N√≥ ho·∫°t ƒë·ªông b·∫±ng c√°ch x√¢y d·ª±ng nhi·ªÅu c√¢y quy·∫øt ƒë·ªãnh trong qu√° tr√¨nh hu·∫•n luy·ªán v√† xu·∫•t ra 
        l·ªõp l√† ch·∫ø ƒë·ªô c·ªßa c√°c l·ªõp (ƒë·ªëi v·ªõi b√†i to√°n ph√¢n lo·∫°i) c·ªßa c√°c c√¢y ri√™ng l·∫ª. 
        Thu·∫≠t to√°n n√†y n·ªïi ti·∫øng v·ªõi ƒë·ªô ch√≠nh x√°c cao v√† kh·∫£ nƒÉng x·ª≠ l√Ω t·ªët c·∫£ d·ªØ li·ªáu s·ªë v√† ph√¢n lo·∫°i, 
        gi√∫p n√≥ tr·ªü th√†nh l·ª±a ch·ªçn l√Ω t∆∞·ªüng cho b√†i to√°n ph√¢n lo·∫°i h·ªçc sinh n√†y.
        </p>
    </div>
    """, unsafe_allow_html=True)
    st.markdown("<p style='text-align: center; color: #E0FFFF; margin-top: 30px;'>C·∫£m ∆°n b·∫°n ƒë√£ s·ª≠ d·ª•ng ·ª©ng d·ª•ng c·ªßa ch√∫ng t√¥i!</p>", unsafe_allow_html=True)


with tab_train_eval:
    st.markdown("## üìä Hu·∫•n luy·ªán & ƒê√°nh gi√° M√¥ h√¨nh")
    st.write("T·∫°i ƒë√¢y, b·∫°n s·∫Ω t·∫£i l√™n d·ªØ li·ªáu hu·∫•n luy·ªán ƒë·ªÉ x√¢y d·ª±ng v√† ƒë√°nh gi√° m√¥ h√¨nh ph√¢n lo·∫°i h·ªçc sinh. Sau khi t·∫£i l√™n, qu√° tr√¨nh ti·ªÅn x·ª≠ l√Ω v√† hu·∫•n luy·ªán s·∫Ω t·ª± ƒë·ªông di·ªÖn ra.")
    
    uploaded_train_file = st.file_uploader(
        "**B∆∞·ªõc 1: T·∫£i l√™n file CSV d·ªØ li·ªáu h·ªçc sinh ƒë·ªÉ hu·∫•n luy·ªán** (V√≠ d·ª•: `student_data.csv`)",
        type=["csv"],
        key="train_file_uploader_main"
    )

    df_processed = None
    grade_encoder = None

    if uploaded_train_file is not None:
        # Check if file content has changed to avoid unnecessary re-processing
        current_file_content = uploaded_train_file.getvalue()
        if st.session_state['uploaded_train_file_content'] != current_file_content:
            st.session_state['uploaded_train_file_content'] = current_file_content
            with st.spinner("ƒêang ƒë·ªçc v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán..."):
                df_processed, grade_encoder = load_and_preprocess_data(io.BytesIO(st.session_state['uploaded_train_file_content']))
                st.session_state['df_processed'] = df_processed # Store processed df in session state
                st.session_state['grade_encoder'] = grade_encoder # Store encoder in session state
            if df_processed is not None and grade_encoder is not None:
                st.success("üéâ Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán ho√†n t·∫•t! S·∫µn s√†ng hu·∫•n luy·ªán m√¥ h√¨nh.")
                train_and_evaluate_model(st.session_state['df_processed'], st.session_state['grade_encoder'])
            else:
                st.error("‚ùå Kh√¥ng th·ªÉ ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ file ƒë√£ t·∫£i l√™n. Vui l√≤ng ki·ªÉm tra l·∫°i file c·ªßa b·∫°n.")
        else: # File content is the same, use cached processed data
            df_processed = st.session_state.get('df_processed')
            grade_encoder = st.session_state.get('grade_encoder')
            if df_processed is not None and grade_encoder is not None:
                st.info("D·ªØ li·ªáu ƒë√£ ƒë∆∞·ª£c ti·ªÅn x·ª≠ l√Ω. ƒêang s·ª≠ d·ª•ng l·∫°i k·∫øt qu·∫£.")
                train_and_evaluate_model(df_processed, grade_encoder)
            else:
                st.warning("D·ªØ li·ªáu ƒë√£ t·∫£i l√™n nh∆∞ng ch∆∞a ƒë∆∞·ª£c x·ª≠ l√Ω. ƒêang x·ª≠ l√Ω l·∫°i.")
                with st.spinner("ƒêang ƒë·ªçc v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán..."):
                    df_processed, grade_encoder = load_and_preprocess_data(io.BytesIO(st.session_state['uploaded_train_file_content']))
                    st.session_state['df_processed'] = df_processed
                    st.session_state['grade_encoder'] = grade_encoder
                if df_processed is not None and grade_encoder is not None:
                    st.success("üéâ Ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu hu·∫•n luy·ªán ho√†n t·∫•t! S·∫µn s√†ng hu·∫•n luy·ªán m√¥ h√¨nh.")
                    train_and_evaluate_model(st.session_state['df_processed'], st.session_state['grade_encoder'])
                else:
                    st.error("‚ùå Kh√¥ng th·ªÉ ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu t·ª´ file ƒë√£ t·∫£i l√™n. Vui l√≤ng ki·ªÉm tra l·∫°i file c·ªßa b·∫°n.")


    else: # No file uploaded initially
        st.info("üí° Vui l√≤ng t·∫£i l√™n file CSV ƒë·ªÉ b·∫Øt ƒë·∫ßu qu√° tr√¨nh hu·∫•n luy·ªán v√† ƒë√°nh gi√° m√¥ h√¨nh. B·∫°n c≈©ng c√≥ th·ªÉ s·ª≠ d·ª•ng d·ªØ li·ªáu m·∫´u.")
        if st.button("Hu·∫•n luy·ªán v·ªõi d·ªØ li·ªáu m·∫´u", key="train_sample_data_button"):
            with st.spinner("ƒêang t·∫£i v√† ti·ªÅn x·ª≠ l√Ω d·ªØ li·ªáu m·∫´u..."):
                df_processed_sample, grade_encoder_sample = load_and_preprocess_data(None) # Pass None to use sample data
            
            if df_processed_sample is not None and grade_encoder_sample is not None:
                st.session_state['df_processed'] = df_processed_sample
                st.session_state['grade_encoder'] = grade_encoder_sample
                st.session_state['uploaded_train_file_content'] = "sample_data_loaded" # Mark that sample data was used
                st.success("‚úÖ ƒê√£ s·ª≠ d·ª•ng d·ªØ li·ªáu m·∫´u ƒë·ªÉ ti·ªÅn x·ª≠ l√Ω. ƒêang hu·∫•n luy·ªán...")
                train_and_evaluate_model(st.session_state['df_processed'], st.session_state['grade_encoder'])
            else:
                st.error("‚ùå Kh√¥ng c√≥ d·ªØ li·ªáu ƒë·ªÉ x·ª≠ l√Ω. Vui l√≤ng t·∫£i l√™n file ho·∫∑c ki·ªÉm tra l·ªói d·ªØ li·ªáu m·∫´u.")


with tab_predict:
    st.markdown("## üîÆ D·ª± ƒëo√°n H·ªçc l·ª±c cho D·ªØ li·ªáu M·ªõi")
    st.write("S·ª≠ d·ª•ng m√¥ h√¨nh ƒë√£ hu·∫•n luy·ªán ƒë·ªÉ d·ª± ƒëo√°n h·ªçc l·ª±c cho d·ªØ li·ªáu h·ªçc sinh m·ªõi c·ªßa b·∫°n. ƒê·∫£m b·∫£o file m·ªõi c√≥ c·∫•u tr√∫c t∆∞∆°ng t·ª± file hu·∫•n luy·ªán.")

    if st.session_state['rf_model'] is not None and \
       st.session_state['X_train_cols'] is not None and \
       st.session_state['grade_encoder'] is not None:
        
        st.success("‚úÖ M√¥ h√¨nh ƒë√£ ƒë∆∞·ª£c hu·∫•n luy·ªán v√† s·∫µn s√†ng ƒë·ªÉ d·ª± ƒëo√°n. Vui l√≤ng t·∫£i l√™n file CSV ƒë·ªÉ nh·∫≠n d·ª± ƒëo√°n.")
        
        uploaded_prediction_file = st.file_uploader(
            "**B∆∞·ªõc 1: T·∫£i l√™n file CSV d·ªØ li·ªáu h·ªçc sinh m·ªõi ƒë·ªÉ d·ª± ƒëo√°n**",
            type=["csv"],
            key="predict_file_uploader_main"
        )

        if uploaded_prediction_file is not None:
            # Check if file content has changed for prediction data as well
            current_predict_file_content = uploaded_prediction_file.getvalue()
            if st.session_state['uploaded_predict_file_content'] != current_predict_file_content:
                st.session_state['uploaded_predict_file_content'] = current_predict_file_content
                new_df = None
                try:
                    new_df = pd.read_csv(io.BytesIO(st.session_state['uploaded_predict_file_content']))
                    if new_df.empty:
                        st.error("File CSV d·ª± ƒëo√°n tr·ªëng. Vui l√≤ng t·∫£i l√™n file c√≥ d·ªØ li·ªáu.")
                        st.stop()
                except Exception as e:
                    st.error(f"L·ªói khi ƒë·ªçc file CSV d·ª± ƒëo√°n: {e}. Vui l√≤ng ki·ªÉm tra ƒë·ªãnh d·∫°ng file.")
                    st.stop()

                st.subheader("3.1. D·ªØ li·ªáu m·ªõi ƒë√£ t·∫£i l√™n:")
                st.dataframe(new_df.head())

                st.subheader("3.2. K·∫øt qu·∫£ d·ª± ƒëo√°n:")

                new_df_processed = new_df.copy()
                
                has_g_cols_new = all(col in new_df_processed.columns for col in ['G1', 'G2', 'G3'])
                has_final_score_new = 'Final_Score' in new_df_processed.columns

                if has_g_cols_new:
                    new_df_processed['total_grade'] = new_df_processed['G1'] + new_df_processed['G2'] + new_df_processed['G3']
                elif has_final_score_new:
                    new_df_processed['total_grade'] = new_df_processed['Final_Score'] / 100 * 60
                else:
                    st.error("‚ùå File d·ª± ƒëo√°n kh√¥ng c√≥ c√°c c·ªôt ƒëi·ªÉm c·∫ßn thi·∫øt (G1, G2, G3 ho·∫∑c Final_Score). Kh√¥ng th·ªÉ d·ª± ƒëo√°n.")
                    st.stop()

                # X·ª≠ l√Ω c√°c c·ªôt object/category
                object_cols_new = new_df_processed.select_dtypes(include=['object', 'category']).columns
                if len(object_cols_new) > 0:
                    new_df_processed = pd.get_dummies(new_df_processed, columns=object_cols_new, drop_first=True, dtype='int')

                # √Åp d·ª•ng log transform cho c√°c c·ªôt s·ªë ƒë√£ ƒë∆∞·ª£c transform trong hu·∫•n luy·ªán
                for col in st.session_state['X_train_cols']:
                    if col in new_df_processed.columns and np.issubdtype(new_df_processed[col].dtype, np.number):
                        # Simple check if the column was likely log-transformed
                        # This is a heuristic; a more robust solution would save the scaler/transformer
                        # or log transformations per column. For now, assume if the skew was high and it's numeric.
                        original_skew = skew(new_df_processed[col].dropna()) # Calculate skew on the new data
                        if abs(original_skew) > 1: # Re-apply the same condition as during training
                             if original_skew > 1:
                                 new_df_processed[col] = np.log1p(new_df_processed[col])


                # ƒê·ªìng b·ªô c·ªôt: th√™m c√°c c·ªôt b·ªã thi·∫øu v√†o d·ªØ li·ªáu m·ªõi v·ªõi gi√° tr·ªã 0
                # v√† lo·∫°i b·ªè c√°c c·ªôt th·ª´a trong d·ªØ li·ªáu m·ªõi kh√¥ng c√≥ trong X_train
                final_predict_df = pd.DataFrame(columns=st.session_state['X_train_cols'])
                for col in st.session_state['X_train_cols']:
                    if col in new_df_processed.columns:
                        final_predict_df[col] = new_df_processed[col]
                    else:
                        final_predict_df[col] = 0 # Fill missing columns with 0

                # Ensure order of columns is same as X_train
                final_predict_df = final_predict_df[st.session_state['X_train_cols']]
                
                # Handle potential infinite values after transformations
                final_predict_df = final_predict_df.replace([np.inf, -np.inf], np.nan).fillna(0) # Fill NaNs with 0 for prediction

                # D·ª± ƒëo√°n
                try:
                    with st.spinner("ƒêang d·ª± ƒëo√°n h·ªçc l·ª±c... üß†"):
                        predictions_encoded = st.session_state['rf_model'].predict(final_predict_df)
                        predictions_decoded = st.session_state['grade_encoder'].inverse_transform(predictions_encoded)
                    
                    new_df['Predicted_Grade'] = predictions_decoded
                    st.dataframe(new_df[['G1', 'G2', 'G3', 'Predicted_Grade']].head(10)) # Show relevant columns

                    st.markdown("#### Ph√¢n ph·ªëi h·ªçc l·ª±c d·ª± ƒëo√°n tr√™n d·ªØ li·ªáu m·ªõi")
                    fig_pred_dist, ax_pred_dist = plt.subplots(figsize=(8, 6))
                    sns.countplot(x=new_df['Predicted_Grade'], ax=ax_pred_dist, order=st.session_state['grade_encoder'].classes_, palette='magma')
                    ax_pred_dist.set_title("Ph√¢n ph·ªëi h·ªçc l·ª±c d·ª± ƒëo√°n")
                    ax_pred_dist.set_xlabel("H·ªçc l·ª±c")
                    ax_pred_dist.set_ylabel("S·ªë l∆∞·ª£ng")
                    st.pyplot(fig_pred_dist)
                    plt.close(fig_pred_dist)

                    csv_output = new_df.to_csv(index=False).encode('utf-8')
                    st.download_button(
                        label="T·∫£i xu·ªëng k·∫øt qu·∫£ d·ª± ƒëo√°n (CSV) üì•",
                        data=csv_output,
                        file_name="predicted_grades.csv",
                        mime="text/csv",
                    )

                except Exception as e:
                    st.error(f"‚ùå ƒê√£ x·∫£y ra l·ªói khi d·ª± ƒëo√°n: {e}")
                    st.write("Vui l√≤ng ki·ªÉm tra l·∫°i c·∫•u tr√∫c file CSV c·ªßa b·∫°n. ƒê·∫£m b·∫£o c√°c c·ªôt ƒë·∫ßu v√†o c·∫ßn thi·∫øt cho m√¥ h√¨nh ƒë√£ c√≥ trong file v√† ki·ªÉu d·ªØ li·ªáu ph√π h·ª£p.")
                    st.write(f"C√°c c·ªôt m√¥ h√¨nh mong ƒë·ª£i: `{', '.join(st.session_state['X_train_cols'])}`")
            else:
                st.info("File d·ªØ li·ªáu d·ª± ƒëo√°n ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n tr∆∞·ªõc ƒë√≥. ƒêang s·ª≠ d·ª•ng l·∫°i k·∫øt qu·∫£.")
        else:
            st.info("üí° T·∫£i l√™n file CSV ƒë·ªÉ nh·∫≠n d·ª± ƒëo√°n.")
    else:
        st.warning("‚ö†Ô∏è M√¥ h√¨nh ch∆∞a ƒë∆∞·ª£c hu·∫•n luy·ªán. Vui l√≤ng chuy·ªÉn ƒë·∫øn tab 'Hu·∫•n luy·ªán & ƒê√°nh gi√° M√¥ h√¨nh' ƒë·ªÉ hu·∫•n luy·ªán m√¥ h√¨nh tr∆∞·ªõc khi d·ª± ƒëo√°n.")
